{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3870c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#######Project#####\n",
    "# Node_feature 1) one hot aa 2) backbone dihedral\n",
    "# Edge_feature 1) Ca_Ca distance 2) 6D feature (trRosetta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0579b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python libraries (pytorch, numpy, etc -- whatever you need to import)\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0231a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "torch.set_num_threads(4) # make it use upto 4 cpus -- to avoid utilizing all CPUs on master node when you run this script on master\n",
    "\n",
    "BATCH_SIZE = 16 # number of batches\n",
    "CROP_SIZE = 64 # If input protein is longer than CROP_SIZE, it will be trimed to have CROP_SIZE residues (i_start:i_start+CROP_SIZE)\n",
    "LR = 0.001 # learning rate (Q. what would happen if you have too high/too small learning rates?)\n",
    "NUM_EPOCHS = 20\n",
    "device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\" # which device to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d8d672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccm  get_CCMraw.py  out  split_train_test.py  task_s  train_s\r\n",
      "err  msa\t    pdb  tar_s\t\t      test_s\r\n"
     ]
    }
   ],
   "source": [
    "!ls /public_data/ml/CATH40/CATH40-20JUN08/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a560eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, list_name):\n",
    "    #데이터셋의 전처리를 해주는 부분\n",
    "        self.root = \"/public_data/ml/CATH40/CATH40-20JUN08/\" # home directory for dataset\n",
    "        self.root2 = \".\"\n",
    "        self.domIDs = [line.strip() for line in open(\"%s/%s\"%(self.root2, list_name))] # items in dataset\n",
    "        \n",
    "        self.msa_dir = \"%s/msa\"%self.root # where can I find msa?\n",
    "        self.ccm_dir = \"%s/ccm\"%self.root # where can I find raw CCM data (coevolution analysis)?\n",
    "        self.pdb_dir = \"%s/pdb\"%self.root # where can I find ground-truth structure?\n",
    "        \n",
    "    def __len__(self):\n",
    "        #데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "        return len(self.domIDs)\n",
    "    \n",
    "    def read_MSA(self, msa_fn):\n",
    "        # Expected outputs:\n",
    "        # - seq_onehot: one-hot encoded query sequence (Length, 20 standard aa + 1 unknown + 1 gap)\n",
    "        # - seq_profile: sequence profile calculated from given MSA (Length, 20 standard aa +1 unknown + 1gap)\n",
    "        a3m_lines = []\n",
    "        with open(msa_fn, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for idx, line in enumerate(lines):\n",
    "                if idx == 0:\n",
    "                    continue\n",
    "                if line.startswith(\">\"):\n",
    "                    index = line[1:].split()[0]\n",
    "                if not line.startswith(\">\"):\n",
    "                    line = re.sub('[a-z]', '', line)\n",
    "                    #ignore lower case, \\n\n",
    "                    a3m_lines.append(line.upper()[:-1])\n",
    "\n",
    "        AA_order = \"ARNDCQEGHILKMFPSTWYVX-\"\n",
    "        # convert letters into numbers\n",
    "        alphabet = np.array(list(AA_order), dtype='|S1').view(np.uint8) # (22)\n",
    "        msa = np.array([list(s) for s in a3m_lines], dtype='|S1').view(np.uint8) # (Nseq, L)\n",
    "        for i in range(alphabet.shape[0]):\n",
    "            msa[msa == alphabet[i]] = i\n",
    "\n",
    "        # treat all unknown characters as gaps\n",
    "        msa[msa > 22] = 20 # (Nseq, Length)\n",
    "\n",
    "        msa = np.eye(22)[msa] # one-hot encoded msa (Nseq, Length, 22)\n",
    "        Nseq = msa.shape[0] # number of sequences in MSA\n",
    "\n",
    "        seq_onehot = msa[0] # one-hot encoded query sequence\n",
    "        seq_prof = msa.sum(axis=0) / float(Nseq) # sequence profile\n",
    "\n",
    "        return seq_onehot, seq_prof\n",
    "        \n",
    "    def read_pdb(self, pdb_fn, L):\n",
    "        # Inputs:\n",
    "        # - pdb_fn: input PDB file to parse\n",
    "        # - L: Length of query protein\n",
    "        #\n",
    "        # Expected outputs:\n",
    "        # - Cb_contact: Cb-Cb contact map (Ca for Gly or residues having missing Cb) (Length, Length)\n",
    "        # - mask: indicates valid pairs or not\n",
    "        #    - In PDB, it can have a missing region (exists in sequence, but not in structure).\n",
    "        #    - You have to consider it during loss calculation\n",
    "        xyz = list()\n",
    "        mask = np.ones([L, L]).astype(float)\n",
    "        cb_contact_list = np.zeros([L, L]).astype(float)\n",
    "        prevNumber = 1\n",
    "        residues = []\n",
    "        with open(pdb_fn) as fp:\n",
    "            for line in fp:\n",
    "                if not line.startswith(\"ATOM\"):\n",
    "                    continue\n",
    "                resName = line[17:20].strip()\n",
    "                atmName = line[12:16].strip()\n",
    "                if resName == \"GLY\":\n",
    "                    if atmName == \"CA\":\n",
    "                        xyz.append([float(line[30:38]), float(line[38:46]), float(line[46:54])])\n",
    "                        residue_id = int(line[22:26].strip())\n",
    "                        chain_id = line[21]\n",
    "                        residues.append((residue_id, chain_id))\n",
    "\n",
    "                else:\n",
    "                    if atmName == \"CB\":\n",
    "                        xyz.append([float(line[30:38]), float(line[38:46]), float(line[46:54])])\n",
    "                        residue_id = int(line[22:26].strip())\n",
    "                        chain_id = line[21]\n",
    "                        residues.append((residue_id, chain_id))\n",
    "        xyz = np.array(xyz)\n",
    "        dist_map = scipy.spatial.distance.cdist(xyz, xyz)\n",
    "        cb_contact = (dist_map < 8.0).astype(float)\n",
    "        len_residue = len(residues)\n",
    "        \n",
    "        if L < len_residue:\n",
    "            print(f\"Fault: Residue length in a3m file is smaller than residue length in pdb {pdb_fn}\")\n",
    "        elif L > len_residue:\n",
    "            mask[len_residue:] = mask[:,len_residue:] = 0\n",
    "        cb_contact_list[0,:len_residue], cb_contact_list[:len_residue,0] = cb_contact[0,:], cb_contact[:,0]\n",
    "        first_id, _ = residues[0]\n",
    "        for i in range(len(residues)-1):\n",
    "            current_residue_id, current_chain_id = residues[i]\n",
    "            next_residue_id, next_chain_id = residues[i + 1]\n",
    "            if (next_chain_id == current_chain_id) and (next_residue_id - current_residue_id > 1):\n",
    "                mask[current_residue_id+1:next_residue_id,:] = mask[:,current_residue_id+1:next_residue_id] = 0\n",
    "            cb_contact_list[next_residue_id-first_id,:len_residue], cb_contact_list[:len_residue,next_residue_id-first_id] = \\\n",
    "                                                                    cb_contact[i+1,:], cb_contact[:,i+1]\n",
    "        return cb_contact_list, mask\n",
    "        \n",
    "    def __getitem__(self, idx): \n",
    "        #데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "        domain = self.domIDs[idx]\n",
    "        msa_fn = \"%s/%s.a3m\"%(self.msa_dir, domain) # msa file for selected domain\n",
    "        ccm_fn = \"%s/%s.npy\"%(self.ccm_dir, domain) # raw ccm file for selected domain\n",
    "        pdb_fn = \"%s/%s.pdb\"%(self.pdb_dir, domain) # raw pdb file for selected domain\n",
    "         \n",
    "        # 1. read MSA & get query sequence + sequence profile & concatenate them to get a 1D feature\n",
    "        # size of feat_1d : (Length, 22+22)\n",
    "        seq_onehot, seq_prof = self.read_MSA(msa_fn)\n",
    "        feat_1d = np.concatenate([seq_onehot, seq_prof], axis=1)\n",
    "\n",
    "        # 2. tile them to make it as 2D feature\n",
    "        L = seq_onehot.shape[0]\n",
    "        tile_x = np.tile(feat_1d[:,np.newaxis,:], (1,L,1))\n",
    "        tile_y = np.tile(feat_1d[:,np.newaxis,:], (1,L,1))\n",
    "        \n",
    "        # 3. read raw CCM (coevolution) data & get 2D input features by concatenating CCM features & tiled 1D features\n",
    "        ccm = np.load(ccm_fn)\n",
    "        feat_2d = torch.from_numpy(np.concatenate((ccm, tile_x, tile_y), axis=-1)) # (L, L, 441+44+44)\n",
    "        \n",
    "        # 3. read pdb & get contacts between Cb atoms (for Gly use Ca instead of Cb)\n",
    "        Cb_contact, mask = self.read_pdb(pdb_fn, L)\n",
    "        Cb_contact, mask = torch.from_numpy(Cb_contact), torch.from_numpy(mask)\n",
    "        # 4. return input features, labels (contact map), and mask information (to calculate loss on valid pairs only)\n",
    "        return feat_2d, Cb_contact, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3519716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dom_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m trainset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, list_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/public_data/ml/CATH40/CATH40-20JUN08/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# home directory for dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomIDs \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;66;03m# items in dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsa_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/msa\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;66;03m# where can I find msa?\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mccm_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/ccm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;66;03m# where can I find raw CCM data (coevolution analysis)?\u001b[39;00m\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_s'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f12325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to define a rule about how to collate batch when proteins have different length\n",
    "# Below is the example. feel free to modify it or use it as-is\n",
    "def collate_batch(batch):\n",
    "    # Input: batch = (input_feat, label, mask)\n",
    "    # Output: Cropped input_feat, label, mask\n",
    "    L_min = min([CROP_SIZE, min([input_feat.shape[0] for (input_feat,_,_) in batch])])\n",
    "\n",
    "    b_input = list()\n",
    "    b_label = list()\n",
    "    b_mask = list()\n",
    "    # crop examples having length > L_min\n",
    "    for input_feat, label, mask in batch:\n",
    "        L = input_feat.shape[0]\n",
    "        if L > L_min:\n",
    "            end_idx_1 = np.random.randint(L_min, L)\n",
    "            end_idx_2 = np.random.randint(L_min, L)\n",
    "        else:\n",
    "            end_idx_1 = L_min\n",
    "            end_idx_2 = L_min\n",
    "        b_input.append(input_feat[end_idx_1-L_min:end_idx_1,end_idx_2-L_min:end_idx_2])\n",
    "        b_label.append(label[end_idx_1-L_min:end_idx_1,end_idx_2-L_min:end_idx_2])\n",
    "        b_mask.append(mask[end_idx_1-L_min:end_idx_1,end_idx_2-L_min:end_idx_2])\n",
    "    a=torch.stack(b_input)\n",
    "    b=torch.stack(b_label)\n",
    "    c= torch.stack(b_mask)\n",
    "    return torch.stack(b_input), torch.stack(b_label), torch.stack(b_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d49b6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader for training set, validation set\n",
    "trainset = CustomDataset(\"train_s\")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "validset = CustomDataset(\"val_s\")\n",
    "validloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True, shuffle=False, collate_fn=collate_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0826312",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 64 102 113 torch.Size([139, 139]) torch.Size([64, 64])\n",
      "257 64 114 168 torch.Size([257, 257]) torch.Size([64, 64])\n",
      "170 64 149 110 torch.Size([170, 170]) torch.Size([64, 64])\n",
      "153 64 93 113 torch.Size([153, 153]) torch.Size([64, 64])\n",
      "371 64 101 234 torch.Size([371, 371]) torch.Size([64, 64])\n",
      "133 64 131 125 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "132 64 123 70 torch.Size([132, 132]) torch.Size([64, 64])\n",
      "362 64 183 117 torch.Size([362, 362]) torch.Size([64, 64])\n",
      "182 64 146 105 torch.Size([182, 182]) torch.Size([64, 64])\n",
      "213 64 204 66 torch.Size([213, 213]) torch.Size([64, 64])\n",
      "161 64 68 119 torch.Size([161, 161]) torch.Size([64, 64])\n",
      "143 64 111 67 torch.Size([143, 143]) torch.Size([64, 64])\n",
      "163 64 114 109 torch.Size([163, 163]) torch.Size([64, 64])\n",
      "201 64 124 130 torch.Size([201, 201]) torch.Size([64, 64])\n",
      "202 64 143 177 torch.Size([202, 202]) torch.Size([64, 64])\n",
      "160 64 103 87 torch.Size([160, 160]) torch.Size([64, 64])\n",
      "251 64 203 210 torch.Size([251, 251]) torch.Size([64, 64])\n",
      "329 64 256 105 torch.Size([329, 329]) torch.Size([64, 64])\n",
      "149 64 131 82 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "208 64 87 196 torch.Size([208, 208]) torch.Size([64, 64])\n",
      "318 64 273 144 torch.Size([318, 318]) torch.Size([64, 64])\n",
      "462 64 124 153 torch.Size([462, 462]) torch.Size([64, 64])\n",
      "142 64 92 108 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "320 64 66 83 torch.Size([320, 320]) torch.Size([64, 64])\n",
      "167 64 103 101 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "167 64 95 162 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "129156 64 152 95 torch.Size([156, 156]) torch.Size([64, 64])\n",
      "291 64 163 256 torch.Size([291, 291]) torch.Size([64, 64])\n",
      " 64 106 82 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "131 64146 64 133 81 torch.Size([146, 146]) torch.Size([64, 64])\n",
      "189 64 102 128 torch.Size([131, 131]) torch.Size([64, 64])\n",
      "157 64 96 127 torch.Size([157, 157]) 106 101 torch.Size([189, 189]) torch.Size([64, 64])\n",
      "181 64 109 67 torch.Size([181, 181])  torch.Size([64, 64])\n",
      "151 64 97 124 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "181 64 152 140 torch.Size([181, 181]) torch.Size([64, 64])\n",
      "510 129 64 64 29399 121 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "239 64  409 150 torch.Size([510, 510]) torch.Size([64, 64])\n",
      "185204 torch.Size([239, 239]) 64  130torch.Size([64, 64]) 169\n",
      " torch.Size([185, 185]) torch.Size([64, 64])\n",
      "138 64 91 73 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "202 64 83 154 torch.Size([202, 202]) torch.Size([64, 64])\n",
      "133 64 66 121 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "308 64 124 78 torch.Size([308, 308]) torch.Size([64, 64])\n",
      "154 64 72 66 torch.Size([154, 154]) torch.Size([64, 64])\n",
      "163 64 79 85 torch.Size([163, 163]) torch.Size([64, 64])\n",
      "218 64 192 205 torch.Size([218, 218]) torch.Size([64, 64])\n",
      "149 64 110 81 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "145 64 118 114 torch.Size([145, 145]) torch.Size([64, 64])\n",
      "158 64 134 121 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "284 64 91 255 torch.Size([284, 284]) torch.Size([64, 64])\n",
      "160 64 124 103 torch.Size([160, 160]) torch.Size([64, 64])\n",
      "178 64 127 106 torch.Size([178, 178]) torch.Size([64, 64])\n",
      "171 64 151 89 torch.Size([171, 171]) torch.Size([64, 64])\n",
      "212 64 210 118 torch.Size([212, 212]) torch.Size([64, 64])\n",
      "288 64 125 103 torch.Size([288, 288]) torch.Size([64, 64])\n",
      "152 64 137 128 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "152 64 137 115 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "219 64 132 76 torch.Size([219, 219]) torch.Size([64, 64])\n",
      "399 64 259 384 torch.Size([399, 399]) torch.Size([64, 64])\n",
      "193 64 125 166 torch.Size([193, 193]) torch.Size([64, 64])\n",
      "192 64 85 145 torch.Size([192, 192]) torch.Size([64, 64])\n",
      "568 64 95 502 torch.Size([568, 568]) torch.Size([64, 64])\n",
      "136 64 128 106 torch.Size([136, 136]) torch.Size([64, 64])\n",
      "195 64 186 84 torch.Size([195, 195]) torch.Size([64, 64])\n",
      "243 64 191 99 torch.Size([243, 243]) torch.Size([64, 64])\n",
      "146 64 103 67 torch.Size([146, 146]) torch.Size([64, 64])\n",
      "221 64 88 73 torch.Size([221, 221]) torch.Size([64, 64])\n",
      "144 64158  11964  10972  115torch.Size([144, 144])  torch.Size([64, 64])torch.Size([158, 158])\n",
      " 133torch.Size([64, 64]) \n",
      "64145 64 85 122 torch.Size([145, 145])  torch.Size([64, 64])126\n",
      " 81135  64torch.Size([133, 133])  127 114 torch.Size([135, 135]) torch.Size([64, 64])\n",
      "135 64 130torch.Size([64, 64]) \n",
      "13690 torch.Size([135, 135]) 64  torch.Size([64, 64])65\n",
      "128 66  64 torch.Size([136, 136]) 75torch.Size([64, 64])\n",
      "149 64 106 126 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "161 64  89 torch.Size([128, 128]) torch.Size([64, 64])\n",
      "161 64 135 117 torch.Size([161, 161]) torch.Size([64, 64])\n",
      "147 64 130 77 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "292 6498 126  25881  torch.Size([292, 292])torch.Size([161, 161])  torch.Size([64, 64])torch.Size([64, 64])\n",
      "\n",
      "189150 64 136 107 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "133 64 64 82 184  torch.Size([189, 189])80  68torch.Size([64, 64])\n",
      " torch.Size([133, 133])279  torch.Size([64, 64])64\n",
      " 150 18264  90133  97 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "176 64 120 71 torch.Size([176, 176]) torch.Size([64, 64])\n",
      "208 64 183 86 torch.Size([208, 208]) torch.Size([64, 64])\n",
      "190torch.Size([279, 279]) torch.Size([64, 64])\n",
      "204 64 141 79 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "200 64 178 74 torch.Size([200, 200]) torch.Size([64, 64])\n",
      "172 64 88  15664  torch.Size([172, 172])161  torch.Size([64, 64])\n",
      "156 64 169 143 torch.Size([190, 190]) 99 torch.Size([64, 64])\n",
      "171 64torch.Size([156, 156])  71torch.Size([64, 64])\n",
      "159  64 84 153 torch.Size([159, 159]) torch.Size([64, 64])\n",
      "133 64 100 89 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "160 torch.Size([171, 171]) torch.Size([64, 64])\n",
      "400 64 197 213 torch.Size([400, 400]) torch.Size([64, 64])\n",
      "263 64 173 125 torch.Size([263, 263]) torch.Size([64, 64])\n",
      "131 64 125 65 torch.Size([131, 131]) torch.Size([64, 64])\n",
      "208 64 158 201 torch.Size([208, 208]) torch.Size([64, 64])\n",
      "321 64 292 210 torch.Size([321, 321]) torch.Size([64, 64])\n",
      "291 64 73 113 torch.Size([291, 291]) torch.Size([64, 64])\n",
      "148 64 123 129 torch.Size([148, 148]) torch.Size([64, 64])\n",
      "142 64 113 127 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "190 64 178 139 torch.Size([190, 190]) torch.Size([64, 64])\n",
      "183 64 172 148 torch.Size([183, 183]) torch.Size([64, 64])\n",
      "207 64 72 199 torch.Size([207, 207]) torch.Size([64, 64])\n",
      "159 64 156 70 torch.Size([159, 159]) torch.Size([64, 64])\n",
      "267 64 215 233 torch.Size([267, 267]) torch.Size([64, 64])\n",
      "198 64 134 168 torch.Size([198, 198]) torch.Size([64, 64])\n",
      "176 64 91 83 torch.Size([176, 176]) torch.Size([64, 64])\n",
      "194 64 166 153 torch.Size([194, 194]) torch.Size([64, 64])\n",
      "258 64 180 257 torch.Size([258, 258]) torch.Size([64, 64])\n",
      "255 64 113 103 torch.Size([255, 255]) torch.Size([64, 64])\n",
      "234 64 200 92 torch.Size([234, 234]) torch.Size([64, 64])\n",
      "180 64 87 166 torch.Size([180, 180]) torch.Size([64, 64])\n",
      "169 64 145 71 torch.Size([169, 169]) torch.Size([64, 64])\n",
      "311 64 117 125 torch.Size([311, 311]) torch.Size([64, 64])\n",
      "147 64 94 91 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "308 64 200 243 torch.Size([308, 308]) torch.Size([64, 64])\n",
      "148 64 128 119 torch.Size([148, 148]) torch.Size([64, 64])\n",
      "160 64 77 94 torch.Size([160, 160]) torch.Size([64, 64])\n",
      "513 64 298 229 torch.Size([513, 513]) torch.Size([64, 64])\n",
      "223 64 106 173 torch.Size([223, 223]) torch.Size([64, 64])\n",
      "252 64 173 90 torch.Size([252, 252]) torch.Size([64, 64])\n",
      "262 64 193 97 torch.Size([262, 262]) torch.Size([64, 64])\n",
      "196 64 86 96 torch.Size([196, 196]) torch.Size([64, 64])\n",
      "163 64 85 77 torch.Size([163, 163]) torch.Size([64, 64])\n",
      "169 64 153 148 torch.Size([169, 169]) torch.Size([64, 64])\n",
      "165 64 164 117 torch.Size([165, 165]) torch.Size([64, 64])\n",
      "153 64 100 73 torch.Size([153, 153]) torch.Size([64, 64])\n",
      "199 64 140 189 torch.Size([199, 199]) torch.Size([64, 64])\n",
      "174 64 76 170 torch.Size([174, 174]) torch.Size([64, 64])\n",
      "243 64 138 76 torch.Size([243, 243]) torch.Size([64, 64])\n",
      "144 64 88 126 torch.Size([144, 144]) torch.Size([64, 64])\n",
      "407 64 209 368 torch.Size([407, 407]) torch.Size([64, 64])\n",
      "132 64 122 131 torch.Size([132, 132]) torch.Size([64, 64])\n",
      "357 64 239 339 torch.Size([357, 357]) torch.Size([64, 64])\n",
      "139 64 116 134 torch.Size([139, 139]) torch.Size([64, 64])\n",
      "215 64 151 82 torch.Size([215, 215]) torch.Size([64, 64])\n",
      "220 64 134 123 torch.Size([220, 220]) torch.Size([64, 64])\n",
      "194 64 182 149 torch.Size([194, 194]) torch.Size([64, 64])\n",
      "149 64 77 111 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "183 64 150 85 torch.Size([183, 183]) torch.Size([64, 64])\n",
      "421 64 121 396 torch.Size([421, 421]) torch.Size([64, 64])\n",
      "167 64 83 161 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "194 64 173 176 torch.Size([194, 194]) torch.Size([64, 64])\n",
      "178 64 152 83 torch.Size([178, 178]) torch.Size([64, 64])\n",
      "201 64 101 173 torch.Size([201, 201]) torch.Size([64, 64])\n",
      "174 64 153 166 torch.Size([174, 174]) torch.Size([64, 64])\n",
      "160 64 66 151 torch.Size([160, 160]) torch.Size([64, 64])\n",
      "255 64 186 112 torch.Size([255, 255]) torch.Size([64, 64])\n",
      "157 64 89 98 torch.Size([157, 157]) torch.Size([64, 64])\n",
      "204 64 77 191 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "199 64 123 103 torch.Size([199, 199]) torch.Size([64, 64])\n",
      "165 64 119 95 torch.Size([165, 165]) torch.Size([64, 64])\n",
      "169 64 85 83 torch.Size([169, 169]) 207torch.Size([64, 64]) \n",
      "64164  6464  8290  89torch.Size([207, 207]) torch.Size([164, 164])  torch.Size([64, 64])torch.Size([64, 64])\n",
      "\n",
      "198142  6464  195128  111114  torch.Size([142, 142])torch.Size([198, 198])  torch.Size([64, 64])torch.Size([64, 64])\n",
      "\n",
      "309131  6464  237111  22469  torch.Size([309, 309])torch.Size([131, 131])  torch.Size([64, 64])torch.Size([64, 64])\n",
      "\n",
      "390 64 313 261 torch.Size([390, 390]) torch.Size([64, 64])\n",
      "164 64 75 141 torch.Size([164, 164]) torch.Size([64, 64])\n",
      "283 64 278 125 torch.Size([283, 283]) torch.Size([64, 64])\n",
      "179 64 121 102 torch.Size([179, 179]) torch.Size([64, 64])\n",
      "357 64 235 185 torch.Size([357, 357]) torch.Size([64, 64])\n",
      "131 64 97 88 torch.Size([131, 131]) torch.Size([64, 64])\n",
      "267 64 114 184 torch.Size([267, 267]) torch.Size([64, 64])\n",
      "150 64 118 67 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "292 64 94 174 torch.Size([292, 292]) torch.Size([64, 64])\n",
      "197 64 185 111 torch.Size([197, 197]) torch.Size([64, 64])\n",
      "211 64 114 89 torch.Size([211, 211]) torch.Size([64, 64])\n",
      "131 64 67 124 torch.Size([131, 131]) torch.Size([64, 64])\n",
      "312 64 112 242 torch.Size([312, 312]) torch.Size([64, 64])\n",
      "191 64 155 73 torch.Size([191, 191]) torch.Size([64, 64])\n",
      "138 64 94 69 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "230 64 80 162 torch.Size([230, 230]) torch.Size([64, 64])\n",
      "291 64 255 258 torch.Size([291, 291]) torch.Size([64, 64])\n",
      "143 64 84 110 torch.Size([143, 143]) torch.Size([64, 64])\n",
      "394 64 197 131 torch.Size([394, 394]) torch.Size([64, 64])\n",
      "360 64 243 213 torch.Size([360, 360]) torch.Size([64, 64])\n",
      "415 64 230 152 torch.Size([415, 415]) torch.Size([64, 64])\n",
      "186 64 111 167 torch.Size([186, 186]) torch.Size([64, 64])\n",
      "419 64 279 279 torch.Size([419, 419]) torch.Size([64, 64])\n",
      "247 64 185 116 torch.Size([247, 247]) torch.Size([64, 64])\n",
      "191 64 74 132 torch.Size([191, 191]) torch.Size([64, 64])\n",
      "319 64 143 107 torch.Size([319, 319]) torch.Size([64, 64])\n",
      "140 64 120 116 torch.Size([140, 140]) torch.Size([64, 64])\n",
      "152 64 113 64 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "154 64 88 133 torch.Size([154, 154]) torch.Size([64, 64])\n",
      "286 64 219 71 torch.Size([286, 286]) torch.Size([64, 64])\n",
      "128 64 95 123 torch.Size([128, 128]) torch.Size([64, 64])\n",
      "155 64 114 80 torch.Size([155, 155]) torch.Size([64, 64])\n",
      "135 64 79 81 torch.Size([135, 135]) torch.Size([64, 64])\n",
      "170 64 92 108 torch.Size([170, 170]) torch.Size([64, 64])\n",
      "171 64 166 118 torch.Size([171, 171]) torch.Size([64, 64])\n",
      "429 64 87 82 torch.Size([429, 429]) torch.Size([64, 64])\n",
      "141 64 116 94 torch.Size([141, 141]) torch.Size([64, 64])\n",
      "205 64 131 203 torch.Size([205, 205]) torch.Size([64, 64])\n",
      "150 64 146 77 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "253 64 79 215 torch.Size([253, 253]) torch.Size([64, 64])\n",
      "171 64 162 134 torch.Size([171, 171]) torch.Size([64, 64])\n",
      "149 64 142 87 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "142 64 87 85 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "207 64 68 95 torch.Size([207, 207]) torch.Size([64, 64])\n",
      "128 64 103 70 torch.Size([128, 128]) torch.Size([64, 64])\n",
      "128 64 110 99 torch.Size([128, 128]) torch.Size([64, 64])\n",
      "440 64 258 88 torch.Size([440, 440]) torch.Size([64, 64])\n",
      "129 64 126 110 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "159 64 94 117 torch.Size([159, 159]) torch.Size([64, 64])\n",
      "186 64 182 148 torch.Size([186, 186]) torch.Size([64, 64])\n",
      "159 64 127 93 torch.Size([159, 159]) torch.Size([64, 64])\n",
      "150 64 142 89 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "162 64 98 68 torch.Size([162, 162]) torch.Size([64, 64])\n",
      "144 64 127 102 torch.Size([144, 144]) torch.Size([64, 64])\n",
      "204 64 76 78 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "247 64 107 202 torch.Size([247, 247]) torch.Size([64, 64])\n",
      "250 64 248 177 torch.Size([250, 250]) torch.Size([64, 64])\n",
      "257 64 212 253 torch.Size([257, 257]) torch.Size([64, 64])\n",
      "192 64 140 131 torch.Size([192, 192]) torch.Size([64, 64])\n",
      "299 64 295 69 torch.Size([299, 299]) torch.Size([64, 64])\n",
      "145 64 130 72 torch.Size([145, 145]) torch.Size([64, 64])\n",
      "175 64 110 137 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "155 64 127 139 torch.Size([155, 155]) torch.Size([64, 64])\n",
      "368 64 234 78 torch.Size([368, 368]) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._shutdown_workers()"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "if w.is_alive():"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182, 182])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AssertionError"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "can only test a child process"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 torch.Size([147, 147])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._shutdown_workers()"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "if w.is_alive():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 torch.Size([166, 166])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AssertionError"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "can only test a child process"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([262, 262])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([64, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._shutdown_workers()"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "if w.is_alive():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assert self._parent_pid == os.getpid(), 'can only test a child process'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([141, 141]) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AssertionError: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "can only test a child process"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64 137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([162, 162])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "if w.is_alive():"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AssertionError"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([146, 146])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "can only test a child process"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "202 64 134 121 torch.Size([202, 202]) torch.Size([64, 64])\n",
      "392 64 365 88 torch.Size([392, 392]) torch.Size([64, 64])\n",
      "190 64 18964 80 torch.Size([190, 190]) torch.Size([64, 64])\n",
      "208 64 162 81 torch.Size([208, 208]) torch.Size([64, 64])\n",
      "254 64 90 230 torch.Size([254, 254]) torch.Size([64, 64]) \n",
      "14564  64138  64115  138torch.Size([189, 189])  torch.Size([145, 145])torch.Size([64, 64]) \n",
      "221torch.Size([64, 64]) \n",
      "64 209 155 torch.Size([221, 221]) torch.Size([64, 64])\n",
      "180 64 68 154 torch.Size([180, 180]) torch.Size([64, 64])\n",
      "286 64 110 185 torch.Size([286, 286]) torch.Size([64, 64])\n",
      "172 64 98 149 torch.Size([172, 172]) torch.Size([64, 64])\n",
      "191 64 101 87 torch.Size([191, 191]) torch.Size([64, 64])\n",
      "147 64 65 105 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "138 64 102 73 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "180 64 173 169 torch.Size([180, 180]) torch.Size([64, 64])\n",
      "397 64 181 160 torch.Size([397, 397]) torch.Size([64, 64])\n",
      "172 64 128 114 torch.Size([172, 172]) torch.Size([64, 64])\n",
      "167 64 120 89 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "228 64 70 114 torch.Size([228, 228]) torch.Size([64, 64])\n",
      "157 64 143 99 torch.Size([157, 157]) torch.Size([64, 64])\n",
      "183 64 146 167 torch.Size([183, 183]) torch.Size([64, 64])\n",
      "592 64 120 586 torch.Size([592, 592]) torch.Size([64, 64])\n",
      "273 64 157 184 torch.Size([273, 273]) torch.Size([64, 64])\n",
      "157 64 148 85 torch.Size([157, 157]) torch.Size([64, 64])\n",
      "133 64 72 102 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "217 64 72 107 torch.Size([217, 217]) torch.Size([64, 64])\n",
      "190 64 188 156 torch.Size([190, 190]) torch.Size([64, 64])\n",
      "135 64 81 101 torch.Size([135, 135]) torch.Size([64, 64])\n",
      "191 64 111 134 torch.Size([191, 191]) torch.Size([64, 64])\n",
      "286 64 136 103 torch.Size([286, 286]) torch.Size([64, 64])\n",
      "371 64 164 172 torch.Size([371, 371]) torch.Size([64, 64])\n",
      "391 64 113 368 torch.Size([391, 391]) torch.Size([64, 64])\n",
      "190 64 100 141 torch.Size([190, 190]) torch.Size([64, 64])\n",
      "136 64 89 133 torch.Size([136, 136]) torch.Size([64, 64])\n",
      "341 64 278 278 torch.Size([341, 341]) torch.Size([64, 64])\n",
      "214 64 73 168 torch.Size([214, 214]) torch.Size([64, 64])\n",
      "155 64 113 117 torch.Size([155, 155]) torch.Size([64, 64])\n",
      "144 64 93 117 torch.Size([144, 144]) torch.Size([64, 64])\n",
      "152 64 89 112 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "224 64 193 100 torch.Size([224, 224]) torch.Size([64, 64])\n",
      "156 64 109 138 torch.Size([156, 156]) torch.Size([64, 64])\n",
      "176 64 140 93 torch.Size([176, 176]) torch.Size([64, 64])\n",
      "158 64 94 116 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "255 64 155 150 torch.Size([255, 255]) torch.Size([64, 64])\n",
      "172 64 101 77 torch.Size([172, 172]) torch.Size([64, 64])\n",
      "177 64 174 96 torch.Size([177, 177]) torch.Size([64, 64])\n",
      "199 64 192 184 torch.Size([199, 199]) torch.Size([64, 64])\n",
      "147 64 111 90 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "142 64 139 68 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "267 64 144 261 torch.Size([267, 267]) torch.Size([64, 64])\n",
      "200 64 183 112 torch.Size([200, 200]) torch.Size([64, 64])\n",
      "230 64 176 168 torch.Size([230, 230]) torch.Size([64, 64])\n",
      "226 64 196 90 torch.Size([226, 226]) torch.Size([64, 64])\n",
      "188 64 141 89 torch.Size([188, 188]) torch.Size([64, 64])\n",
      "246 64 69 68 torch.Size([246, 246]) torch.Size([64, 64])\n",
      "228 64 109 177 torch.Size([228, 228]) torch.Size([64, 64])\n",
      "186 64 160 138 torch.Size([186, 186]) torch.Size([64, 64])\n",
      "159 64 81 135 torch.Size([159, 159]) torch.Size([64, 64])\n",
      "363 64 224 298 torch.Size([363, 363]) torch.Size([64, 64])\n",
      "151 64 87 75 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "225 64 121 108 torch.Size([225, 225]) torch.Size([64, 64])\n",
      "194 64 145 150 torch.Size([194, 194]) torch.Size([64, 64])\n",
      "164 64 115 156 torch.Size([164, 164]) torch.Size([64, 64])\n",
      "188 64 95 71 torch.Size([188, 188]) torch.Size([64, 64])\n",
      "244 64 166 64 torch.Size([244, 244]) torch.Size([64, 64])\n",
      "175 64 136 97 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "184 64 126 123 torch.Size([184, 184]) torch.Size([64, 64])\n",
      "184 64 171 133 torch.Size([184, 184]) torch.Size([64, 64])\n",
      "130 64 68 110 torch.Size([130, 130]) torch.Size([64, 64])\n",
      "163 64 130 67 torch.Size([163, 163]) torch.Size([64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 64 147 128 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "388 64 275 74 torch.Size([388, 388]) torch.Size([64, 64])\n",
      "147 64 83 136 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "128 64 94 89 torch.Size([128, 128]) torch.Size([64, 64])\n",
      "291 64 123 73 torch.Size([291, 291]) torch.Size([64, 64])\n",
      "252 64 68 177 torch.Size([252, 252]) torch.Size([64, 64])\n",
      "458 64 384 446 torch.Size([458, 458]) torch.Size([64, 64])\n",
      "237 64 209 171 torch.Size([237, 237]) torch.Size([64, 64])\n",
      "188 64 163 182 torch.Size([188, 188]) torch.Size([64, 64])\n",
      "391 64 77 295 torch.Size([391, 391]) torch.Size([64, 64])\n",
      "215 64 133 169 torch.Size([215, 215]) torch.Size([64, 64])\n",
      "264 64 134 125 torch.Size([264, 264]) torch.Size([64, 64])\n",
      "220 64 181 130 torch.Size([220, 220]) torch.Size([64, 64])\n",
      "279 64 78 103 torch.Size([279, 279]) torch.Size([64, 64])\n",
      "149 64 142 105 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "233 64 220 125 torch.Size([233, 233]) torch.Size([64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 64 159 107 torch.Size([173, 173]) torch.Size([64, 64])\n",
      "160 64 146 151 torch.Size([160, 160]) torch.Size([64, 64])\n",
      "197 64 73 174 torch.Size([197, 197]) torch.Size([64, 64])\n",
      "140 64 88 107 torch.Size([140, 140]) torch.Size([64, 64])\n",
      "181 64 160 162 torch.Size([181, 181]) torch.Size([64, 64])\n",
      "151 64 134 129 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "141 64 125 140 torch.Size([141, 141]) torch.Size([64, 64])\n",
      "200 64 139 185 torch.Size([200, 200]) torch.Size([64, 64])\n",
      "161 64 147 129 torch.Size([161, 161]) torch.Size([64, 64])\n",
      "134 64 65 100 torch.Size([134, 134]) torch.Size([64, 64])\n",
      "532 64 202 512 torch.Size([532, 532]) torch.Size([64, 64])\n",
      "139 64 79 97 torch.Size([139, 139]) torch.Size([64, 64])\n",
      "153 64 106 114 torch.Size([153, 153]) torch.Size([64, 64])\n",
      "137 64 104 70 torch.Size([137, 137]) torch.Size([64, 64])\n",
      "152 64 68 140 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "142 64 102 68 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "228 64 103 194 torch.Size([228, 228]) torch.Size([64, 64])\n",
      "133 64 105 79 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "291 64 66 86 torch.Size([291, 291]) torch.Size([64, 64])\n",
      "266 64 257 225 torch.Size([266, 266]) torch.Size([64, 64])\n",
      "156 64 104 129 torch.Size([156, 156]) torch.Size([64, 64])\n",
      "147 64 88 97 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "142 64 128 123 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "175 64 129 97 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "197 64 68 112 torch.Size([197, 197]) torch.Size([64, 64])\n",
      "138 64 134 91 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "227 64 64 217 torch.Size([227, 227]) torch.Size([64, 64])\n",
      "186 64 181 82 torch.Size([186, 186]) torch.Size([64, 64])\n",
      "211 64 120 155 torch.Size([211, 211]) torch.Size([64, 64])\n",
      "264 64 147 127 torch.Size([264, 264]) torch.Size([64, 64])\n",
      "138 64 85 91 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "245 64 151 185 torch.Size([245, 245]) torch.Size([64, 64])\n",
      "410 64 344 277 torch.Size([410, 410]) torch.Size([64, 64])\n",
      "145 64 133 85 torch.Size([145, 145]) torch.Size([64, 64])\n",
      "206 64 125 120 torch.Size([206, 206]) torch.Size([64, 64])\n",
      "170 64 103 168 torch.Size([170, 170]) torch.Size([64, 64])\n",
      "476 64 269 241 torch.Size([476, 476]) torch.Size([64, 64])\n",
      "218 64 174 176 torch.Size([218, 218]) torch.Size([64, 64])\n",
      "254 64 153 151 torch.Size([254, 254]) torch.Size([64, 64])\n",
      "176 64 163 87 torch.Size([176, 176]) torch.Size([64, 64])\n",
      "306 64 83 108 torch.Size([306, 306]) torch.Size([64, 64])\n",
      "182 64 150 167 torch.Size([182, 182]) torch.Size([64, 64])\n",
      "204 64 140 137 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "171 64 82 150 torch.Size([171, 171]) torch.Size([64, 64])\n",
      "209 64 97 204 torch.Size([209, 209]) torch.Size([64, 64])\n",
      "248 64 120 100 torch.Size([248, 248]) torch.Size([64, 64])\n",
      "154 64 107 126 torch.Size([154, 154]) torch.Size([64, 64])\n",
      "158 64 85 147 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "243 64 160 240 torch.Size([243, 243]) torch.Size([64, 64])\n",
      "230 64 160 146 torch.Size([230, 230]) torch.Size([64, 64])\n",
      "145 64 72 85 torch.Size([145, 145]) torch.Size([64, 64])\n",
      "191 64 94 81 torch.Size([191, 191]) torch.Size([64, 64])\n",
      "152 64 101 147 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "338 64 308 304 torch.Size([338, 338]) torch.Size([64, 64])\n",
      "265 64 209 203 torch.Size([265, 265]) torch.Size([64, 64])\n",
      "167 64 123 75 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "193 64 82 123 torch.Size([193, 193]) torch.Size([64, 64])\n",
      "522 64 337 370 torch.Size([522, 522]) torch.Size([64, 64])\n",
      "130 64 79 129 torch.Size([130, 130]) torch.Size([64, 64])\n",
      "134 64 79 73 torch.Size([134, 134]) torch.Size([64, 64])\n",
      "162 64 77 103 torch.Size([162, 162]) torch.Size([64, 64])\n",
      "224 64 142 103 torch.Size([224, 224]) torch.Size([64, 64])\n",
      "129 64 66 97 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "271 64 76 176 torch.Size([271, 271]) torch.Size([64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff066169d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1449, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346 64 279 345 torch.Size([346, 346]) torch.Size([64, 64])\n",
      "196 64 143 158 torch.Size([196, 196]) torch.Size([64, 64])\n",
      "315 64 65 212 torch.Size([315, 315]) torch.Size([64, 64])\n",
      "151 64 111 145 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "309 64 235 86 torch.Size([309, 309]) torch.Size([64, 64])\n",
      "152 64 142 81 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "137 64 86 73 torch.Size([137, 137]) torch.Size([64, 64])\n",
      "212 64 138 144 torch.Size([212, 212]) torch.Size([64, 64])\n",
      "160 64 153 144 torch.Size([160, 160]) torch.Size([64, 64])\n",
      "236 64 184 67 torch.Size([236, 236]) torch.Size([64, 64])\n",
      "136 64 132 124 torch.Size([136, 136]) torch.Size([64, 64])\n",
      "162 64 148 67 torch.Size([162, 162]) torch.Size([64, 64])\n",
      "188 64 98 112 torch.Size([188, 188]) torch.Size([64, 64])\n",
      "216 64 94 156 torch.Size([216, 216]) torch.Size([64, 64])\n",
      "132 64 114 127 torch.Size([132, 132]) torch.Size([64, 64])\n",
      "138 64 70 108 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "206 64 105 138 torch.Size([206, 206]) torch.Size([64, 64])\n",
      "367 64 123 366 torch.Size([367, 367]) torch.Size([64, 64])\n",
      "158 64 142 156 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "167 64 152 139 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "172 64 166 135 torch.Size([172, 172]) torch.Size([64, 64])\n",
      "230 64 95 186 torch.Size([230, 230]) torch.Size([64, 64])\n",
      "308 64 96 224 torch.Size([308, 308]) torch.Size([64, 64])\n",
      "167 64 147 114 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "361 64 170 70 torch.Size([361, 361]) torch.Size([64, 64])\n",
      "151 64 103 112 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "204 64 142 71 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "192 64 108 69 torch.Size([192, 192]) torch.Size([64, 64])\n",
      "134 64 131 121 torch.Size([134, 134]) torch.Size([64, 64])\n",
      "216 64 187 65 torch.Size([216, 216]) torch.Size([64, 64])\n",
      "204 64 109 110 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "174 64 148 95 torch.Size([174, 174]) torch.Size([64, 64])\n",
      "175 64 89 116 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "317 64 108 149 torch.Size([317, 317]) torch.Size([64, 64])\n",
      "144 64 104 83 torch.Size([144, 144]) torch.Size([64, 64])\n",
      "259 64 145 100 torch.Size([259, 259]) torch.Size([64, 64])\n",
      "197 64 93 110 torch.Size([197, 197]) torch.Size([64, 64])\n",
      "241 64 236 81 torch.Size([241, 241]) torch.Size([64, 64])\n",
      "293 64 193 217 torch.Size([293, 293]) torch.Size([64, 64])\n",
      "215 64 116 200 torch.Size([215, 215]) torch.Size([64, 64])\n",
      "220 64 200 97 torch.Size([220, 220]) torch.Size([64, 64])\n",
      "266 64 134 130 torch.Size([266, 266]) torch.Size([64, 64])\n",
      "259 64 174 90 torch.Size([259, 259]) torch.Size([64, 64])\n",
      "293 64 246 264 torch.Size([293, 293]) torch.Size([64, 64])\n",
      "172 64 102 136 torch.Size([172, 172]) torch.Size([64, 64])\n",
      "149 64 118 64 torch.Size([149, 149]) torch.Size([64, 64])\n",
      "161 64 124 94 torch.Size([161, 161]) torch.Size([64, 64])\n",
      "286 64 259 144 torch.Size([286, 286]) torch.Size([64, 64])\n",
      "129 64 114 86 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "176 28264 134 86 torch.Size([176, 176]) torch.Size([64, 64])\n",
      "162 64 90 102 torch.Size([162, 162]) torch.Size([64, 64])\n",
      "200 64 164 114 torch.Size([200, 200])  torch.Size([64, 64])\n",
      "64143  64157 65  91 torch.Size([143, 143]) torch.Size([64, 64])\n",
      "166 64 152 117 torch.Size([166, 166]) torch.Size([64, 64])\n",
      "194 64 139 154 torch.Size([194, 194]) torch.Size([64, 64])\n",
      "175 64 127128 142 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "280 64 109 101 torch.Size([280, 280]) torch.Size([64, 64])\n",
      "246 64 88  66 torch.Size([282, 282])torch.Size([246, 246]) torch.Size([64, 64]) \n",
      "torch.Size([64, 64])\n",
      "195 15864  64121  71 torch.Size([195, 195]) torch.Size([64, 64])\n",
      "137 64 69 110 torch.Size([137, 137]) torch.Size([64, 64])\n",
      "158 64 152115 90 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "130 64 121 75 torch.Size([130, 130])  torch.Size([64, 64])126\n",
      "404  torch.Size([158, 158])64 torch.Size([64, 64]) \n",
      "139292  19764  torch.Size([404, 404])277 torch.Size([64, 64])\n",
      "466 64 184 404 torch.Size([466, 466]) torch.Size([64, 64]) \n",
      "285 64 214 264 torch.Size([285, 285]) torch.Size([64, 64])\n",
      "144 21464  110torch.Size([292, 292])  67torch.Size([64, 64]) \n",
      "torch.Size([144, 144])216  torch.Size([64, 64])64\n",
      " 74 223 17364  torch.Size([216, 216]) 197torch.Size([64, 64])\n",
      " 67184  64torch.Size([223, 223]) torch.Size([64, 64])\n",
      " 117 81 torch.Size([184, 184]) torch.Size([64, 64])\n",
      "158 64 114 137 64 108 122 torch.Size([137, 137]) torch.Size([64, 64])\n",
      "176 6479  65torch.Size([158, 158])  136torch.Size([64, 64]) \n",
      "torch.Size([176, 176])156  torch.Size([64, 64])64\n",
      " 199143  6470  73torch.Size([156, 156])  torch.Size([64, 64])66\n",
      " torch.Size([199, 199]) torch.Size([64, 64])\n",
      "259 64 173 256 torch.Size([259, 259]) torch.Size([64, 64])\n",
      "141 64 134 70 torch.Size([141, 141]) torch.Size([64, 64])\n",
      "188 64 179 132 torch.Size([188, 188]) torch.Size([64, 64])\n",
      "133 64 73 76 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "282 64 242 202 torch.Size([282, 282]) torch.Size([64, 64])\n",
      "179 64 133 162 torch.Size([179, 179]) torch.Size([64, 64])\n",
      "143 64 128 90 torch.Size([143, 143]) torch.Size([64, 64])\n",
      "151 64 85 117 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "144 64 115 105 torch.Size([144, 144]) torch.Size([64, 64])\n",
      "217 64 113 83 torch.Size([217, 217]) torch.Size([64, 64])\n",
      "379 64 359 240 torch.Size([379, 379]) torch.Size([64, 64])\n",
      "134 64 71 67 torch.Size([134, 134]) torch.Size([64, 64])\n",
      "152 64 72 85 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "236 64 81 193 torch.Size([236, 236]) torch.Size([64, 64])\n",
      "189 64 165 162 torch.Size([189, 189]) torch.Size([64, 64])\n",
      "155 64 117 101 torch.Size([155, 155]) torch.Size([64, 64])\n",
      "133 64 103 115 torch.Size([133, 133]) torch.Size([64, 64])\n",
      "205 64 173 157 torch.Size([205, 205]) torch.Size([64, 64])\n",
      "184 64 81 65 torch.Size([184, 184]) torch.Size([64, 64])\n",
      "361 64 166 328 torch.Size([361, 361]) torch.Size([64, 64])\n",
      "184 64 144 69 torch.Size([184, 184]) torch.Size([64, 64])\n",
      "328 64 299 297 torch.Size([328, 328]) torch.Size([64, 64])\n",
      "365 64 169 289 torch.Size([365, 365]) torch.Size([64, 64])\n",
      "163 64 129 128 torch.Size([163, 163]) torch.Size([64, 64])\n",
      "256 64 132 142 torch.Size([256, 256]) torch.Size([64, 64])\n",
      "282 64 236 75 torch.Size([282, 282]) torch.Size([64, 64])\n",
      "206 64 108 163 torch.Size([206, 206]) torch.Size([64, 64])\n",
      "416 64 130 338 torch.Size([416, 416]) torch.Size([64, 64])\n",
      "326 64 91 260 torch.Size([326, 326]) torch.Size([64, 64])\n",
      "335 64 130 178 torch.Size([335, 335]) torch.Size([64, 64])\n",
      "323 64 129 118 torch.Size([323, 323]) torch.Size([64, 64])\n",
      "387 64 92 134 torch.Size([387, 387]) torch.Size([64, 64])\n",
      "169 64 105 159 torch.Size([169, 169]) torch.Size([64, 64])\n",
      "138 64 111 105 torch.Size([138, 138]) torch.Size([64, 64])\n",
      "298 64 82 253 torch.Size([298, 298]) torch.Size([64, 64])\n",
      "239 64 81 234 torch.Size([239, 239]) torch.Size([64, 64])\n",
      "144 64 124 128 torch.Size([144, 144]) torch.Size([64, 64])\n",
      "236 64 132 232 torch.Size([236, 236]) torch.Size([64, 64])\n",
      "139 64 82 75 torch.Size([139, 139]) torch.Size([64, 64])\n",
      "147 64 131 78 torch.Size([147, 147]) torch.Size([64, 64])\n",
      "283 64 253 212 torch.Size([283, 283]) torch.Size([64, 64])\n",
      "356 64 306 307 torch.Size([356, 356]) torch.Size([64, 64])\n",
      "142 64 123 84 torch.Size([142, 142]) torch.Size([64, 64])\n",
      "242 64 210 197 torch.Size([242, 242]) torch.Size([64, 64])\n",
      "146 64 80 85 torch.Size([146, 146]) torch.Size([64, 64])\n",
      "158 64 126 128 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "132 64 95 116 torch.Size([132, 132]) torch.Size([64, 64])\n",
      "151 64 128 105 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "221 64 74 144 torch.Size([221, 221]) torch.Size([64, 64])\n",
      "241 64 189 92 torch.Size([241, 241]) torch.Size([64, 64])\n",
      "253 64 65 151 torch.Size([253, 253]) torch.Size([64, 64])\n",
      "226 64 210 180 torch.Size([226, 226]) torch.Size([64, 64])\n",
      "136 64 118 64 torch.Size([136, 136]) torch.Size([64, 64])\n",
      "188 64 166 101 torch.Size([188, 188]) torch.Size([64, 64])\n",
      "157 64 72 119 torch.Size([157, 157]) torch.Size([64, 64])\n",
      "279 64 210 160 torch.Size([279, 279]) torch.Size([64, 64])\n",
      "198 64 71 189 torch.Size([198, 198]) torch.Size([64, 64])\n",
      "141 64 88 131 torch.Size([141, 141]) torch.Size([64, 64])\n",
      "145 64 92 104 torch.Size([145, 145]) torch.Size([64, 64])\n",
      "192 64 105 138 torch.Size([192, 192]) torch.Size([64, 64])\n",
      "175 64 95 137 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "158 64 130 68 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "204 64 72 90 torch.Size([204, 204]) torch.Size([64, 64])\n",
      "155 64 154 113 torch.Size([155, 155]) torch.Size([64, 64])\n",
      "257 64 160 158 torch.Size([257, 257]) torch.Size([64, 64])\n",
      "283 64 231 86 torch.Size([283, 283]) torch.Size([64, 64])\n",
      "388 64 93 218 torch.Size([388, 388]) torch.Size([64, 64])\n",
      "194 64 107 68 torch.Size([194, 194]) torch.Size([64, 64])\n",
      "182 64 109 121 torch.Size([182, 182]) torch.Size([64, 64])\n",
      "129 64 81 118 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "146 64 92 115 torch.Size([146, 146]) torch.Size([64, 64])\n",
      "158 64 93 95 torch.Size([158, 158]) torch.Size([64, 64])\n",
      "168 64 69 103 torch.Size([168, 168]) torch.Size([64, 64])\n",
      "225 64 92 84 torch.Size([225, 225]) torch.Size([64, 64])\n",
      "402 64 123 368 torch.Size([402, 402]) torch.Size([64, 64])\n",
      "150 64 65 127 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "128 64 87 115 torch.Size([128, 128]) torch.Size([64, 64])\n",
      "391 64 287 125 torch.Size([391, 391]) torch.Size([64, 64])\n",
      "129 64 119 112 torch.Size([129, 129]) torch.Size([64, 64])\n",
      "175 64 109 160 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "348 64 154 148 torch.Size([348, 348]) torch.Size([64, 64])\n",
      "140 64 137 95 torch.Size([140, 140]) torch.Size([64, 64])\n",
      "130 64 96 77 torch.Size([130, 130]) torch.Size([64, 64])\n",
      "150 64 98 136 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "208 64 93 165 torch.Size([208, 208]) torch.Size([64, 64])\n",
      "259 64 241 167 torch.Size([259, 259]) torch.Size([64, 64])\n",
      "284 64 177 87 torch.Size([284, 284]) torch.Size([64, 64])\n",
      "153 64 86 119 torch.Size([153, 153]) torch.Size([64, 64])\n",
      "169 64 137 115 torch.Size([169, 169]) torch.Size([64, 64])\n",
      "187 64 113 144 torch.Size([187, 187]) torch.Size([64, 64])\n",
      "182 64 66 92 torch.Size([182, 182]) torch.Size([64, 64])\n",
      "140 64 86 66 torch.Size([140, 140]) torch.Size([64, 64])\n",
      "167 64 72 161 torch.Size([167, 167]) torch.Size([64, 64])\n",
      "178 64 133 122 torch.Size([178, 178]) torch.Size([64, 64])\n",
      "145 64 69 96 torch.Size([145, 145]) torch.Size([64, 64])\n",
      "175 64 92 170 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "180 64 142 159 torch.Size([180, 180]) torch.Size([64, 64])\n",
      "209 64 198 89 torch.Size([209, 209]) torch.Size([64, 64])\n",
      "139 64 106 123 torch.Size([139, 139]) torch.Size([64, 64])\n",
      "210 64 193 80 torch.Size([210, 210]) torch.Size([64, 64])\n",
      "151 64 109 115 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "185 64 108 127 torch.Size([185, 185]) torch.Size([64, 64])\n",
      "266 64 256 124 torch.Size([266, 266]) torch.Size([64, 64])\n",
      "198 64 113 131 torch.Size([198, 198]) torch.Size([64, 64])\n",
      "361 64 131 202 torch.Size([361, 361]) torch.Size([64, 64])\n",
      "320 64 119 69 torch.Size([320, 320]) torch.Size([64, 64])\n",
      "325 64 282 134 torch.Size([325, 325]) torch.Size([64, 64])\n",
      "343 64 131 121 torch.Size([343, 343]) torch.Size([64, 64])\n",
      "333 64 76 178 torch.Size([333, 333]) torch.Size([64, 64])\n",
      "157 64 134 112 torch.Size([157, 157]) torch.Size([64, 64])\n",
      "470 64 223 335 torch.Size([470, 470]) torch.Size([64, 64])\n",
      "288 64 130 131 torch.Size([288, 288]) torch.Size([64, 64])\n",
      "223 64 112 182 torch.Size([223, 223]) torch.Size([64, 64])\n",
      "253 64 164 217 torch.Size([253, 253]) torch.Size([64, 64])\n",
      "152 64 73 71 torch.Size([152, 152]) torch.Size([64, 64])\n",
      "175 64 148 68 torch.Size([175, 175]) torch.Size([64, 64])\n",
      "195 64 90 178 torch.Size([195, 195]) torch.Size([64, 64])\n",
      "467 64 365 351 torch.Size([467, 467]) torch.Size([64, 64])\n",
      "283 64 196 271 torch.Size([283, 283]) torch.Size([64, 64])\n",
      "195 64 180 127 torch.Size([195, 195]) torch.Size([64, 64])\n",
      "156 64 110 65 torch.Size([156, 156]) torch.Size([64, 64])\n",
      "347 64 303 158 torch.Size([347, 347]) torch.Size([64, 64])\n",
      "131 64 107 95 torch.Size([131, 131]) torch.Size([64, 64])\n",
      "280 64 67 213 torch.Size([280, 280]) torch.Size([64, 64])\n",
      "134 64 129 107 torch.Size([134, 134]) torch.Size([64, 64])\n",
      "242 64 213 162 torch.Size([242, 242]) torch.Size([64, 64])\n",
      "199 64 137 181 torch.Size([199, 199]) torch.Size([64, 64])\n",
      "240 64 176 178 torch.Size([240, 240]) torch.Size([64, 64])\n",
      "365 64 64 206 torch.Size([365, 365]) torch.Size([64, 64])\n",
      "238 64 121 93 torch.Size([238, 238]) torch.Size([64, 64])\n",
      "200 64 103 117 torch.Size([200, 200]) torch.Size([64, 64])\n",
      "148 64 108 74 torch.Size([148, 148]) torch.Size([64, 64])\n",
      "159 64 69 137 torch.Size([159, 159]) torch.Size([64, 64])\n",
      "180 64 123 112 torch.Size([180, 180]) torch.Size([64, 64])\n",
      "154 64 69 94 torch.Size([154, 154]) torch.Size([64, 64])\n",
      "130 64 72 72 torch.Size([130, 130]) torch.Size([64, 64])\n",
      "166 64 66 140 torch.Size([166, 166]) torch.Size([64, 64])\n",
      "178 64 123 149 torch.Size([178, 178]) torch.Size([64, 64])\n",
      "226 64 186 149 torch.Size([226, 226]) torch.Size([64, 64])\n",
      "151 64 70 126 torch.Size([151, 151]) torch.Size([64, 64])\n",
      "268 64 184 162 torch.Size([268, 268]) torch.Size([64, 64])\n",
      "150 64 64 129 torch.Size([150, 150]) torch.Size([64, 64])\n",
      "132 64 115 99 torch.Size([132, 132]) torch.Size([64, 64])\n",
      "195 64 114 68 torch.Size([195, 195]) torch.Size([64, 64])\n",
      "238 64 150 230 torch.Size([238, 238]) torch.Size([64, 64])\n",
      "179 64 122 135 torch.Size([179, 179]) torch.Size([64, 64])\n",
      "128 64 95 64 torch.Size([128, 128]) torch.Size([64, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_batch, (inputs, labels, masks) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     23\u001b[0m     inputs, labels, masks \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor), labels\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor), masks\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\n\u001b[1;32m     25\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# for Convolution layer in pytorch, input should have (Batch, feature dimension, H, W)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/anaconda3/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Training data -- Prepared\n",
    "# 2. Data loader -- process input features & labels\n",
    "# 3. Deep learning model\n",
    "# 4. Optimizer\n",
    "# 5. Loss function\n",
    "\n",
    "LR = 0.001\n",
    "\n",
    "# Get AI model to be trained\n",
    "# You need to change **...** part!\n",
    "model = ContactPredictor().to(device)\n",
    "\n",
    "# define loss function to use (which loss you need to use?)\n",
    "criterion =  nn.CrossEntropyLoss() # please check https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "for i_epoch in range(NUM_EPOCHS):\n",
    "    avg_loss = 0.0\n",
    "    model.train()\n",
    "    for i_batch, (inputs, labels, masks) in enumerate(trainloader):\n",
    "        inputs, labels, masks = inputs.type(torch.FloatTensor), labels.type(torch.FloatTensor), masks.type(torch.FloatTensor)\n",
    "        \n",
    "        inputs = inputs.permute(0,3,1,2).to(device, non_blocking=True) # for Convolution layer in pytorch, input should have (Batch, feature dimension, H, W)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = (criterion(outputs, labels)*masks).sum() / masks.sum() # use mask to ignore missing regions\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.detach()\n",
    "    avg_loss = avg_loss / len(trainloader)\n",
    "    print (\"Train\", i_epoch, avg_loss.item())\n",
    "    \n",
    "    # Check validation loss\n",
    "    model.eval()\n",
    "    avg_loss = 0.0\n",
    "    with torch.no_grad(): # you don't need to calculate gradient for validation\n",
    "        for i_batch, (inputs, labels, masks) in enumerate(validloader):\n",
    "            inputs = inputs.permute(0,3,1,2).to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = (criterion(outputs, labels)*masks).sum() / masks.sum()\n",
    "\n",
    "            avg_loss += loss.detach()\n",
    "    avg_loss = avg_loss / len(validloader)\n",
    "    print (\"valid\", i_epoch, avg_loss.item())\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': i_epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "                }, '.')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a027719",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1f3adadbf25c62fc6f766b52b851325b8c1f90b123eb2555aa3b6b591ae4ccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
